<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on </title>
    <link>/tags/python/</link>
    <description>Recent content in Python on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Aug 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>分形理论</title>
      <link>/2018/08/iteration_fractal/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/iteration_fractal/</guid>
      <description>&lt;p&gt;分形简单来说就是具有自相似性质的图形, 其Hausdorff 维度一般来说是分数的, 与常规认知的维度不同.
我虽然很早就接触过分形, 但是并没有画过分形的图, 这里写一下画分形的代码&amp;hellip;先介绍一个简单的分形图形, 再说说经典的Julia集合, Kuch 雪花曲线等等&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>牛顿法求解极小值</title>
      <link>/2018/08/%E7%89%9B%E9%A1%BF%E6%B3%95%E6%B1%82%E8%A7%A3%E6%9E%81%E5%B0%8F%E5%80%BC/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/%E7%89%9B%E9%A1%BF%E6%B3%95%E6%B1%82%E8%A7%A3%E6%9E%81%E5%B0%8F%E5%80%BC/</guid>
      <description>&lt;p&gt;这一节我们来使用牛顿法做优化, 之前在一维搜索方法中提到过牛顿法, 即为使用二次函数来近似某点周围的函数, 从而达到简化问题的效果. 本节也是通过类似的方法来实现函数的极值的求解的.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>梯度下降法求解函数极小值-1</title>
      <link>/2018/08/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E6%B1%82%E8%A7%A3%E5%87%BD%E6%95%B0%E6%9E%81%E5%B0%8F%E5%80%BC-1/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E6%B1%82%E8%A7%A3%E5%87%BD%E6%95%B0%E6%9E%81%E5%B0%8F%E5%80%BC-1/</guid>
      <description>&lt;p&gt;我们知道, 函数沿着负梯度方向下降是最快的, 因此利用梯度下降法是计算函数极小值的常用的方法.因此如果我们确定一个初始点\(x_0\), 那么利用迭代公式:&lt;/p&gt;

&lt;p&gt;$$x_{k+1} = x_k - \alpha_k \nabla f(x_k) $$&lt;/p&gt;

&lt;p&gt;其中\(\alpha_k\)为步长.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>一维函数的极小值搜索方法</title>
      <link>/2018/08/%E4%B8%80%E7%BB%B4%E5%87%BD%E6%95%B0%E7%9A%84%E6%9E%81%E5%B0%8F%E5%80%BC%E6%90%9C%E7%B4%A2%E6%96%B9%E6%B3%95/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/%E4%B8%80%E7%BB%B4%E5%87%BD%E6%95%B0%E7%9A%84%E6%9E%81%E5%B0%8F%E5%80%BC%E6%90%9C%E7%B4%A2%E6%96%B9%E6%B3%95/</guid>
      <description>&lt;p&gt;求一个函数的极小值或者是最小值一般来说是一个很复杂的问题, 涉及到全局优化的问题, 从最开始的梯度下降, 共轭梯度, 牛顿法以及衍生出来的准牛顿法等等都可以较好地搜索到局域极小值. 这里我们先以一元函数为例, 简述求解其极小值的几种方法.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>numpy中读取文件的两种方法, loadtxt和genfromtxt</title>
      <link>/2018/08/numpy%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95-loadtxt%E5%92%8Cgenfromtxt/</link>
      <pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/numpy%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95-loadtxt%E5%92%8Cgenfromtxt/</guid>
      <description>&lt;p&gt;numpy中有两个函数可以用来读取txt文件, 下面主要来介绍这两个函数的用法.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>